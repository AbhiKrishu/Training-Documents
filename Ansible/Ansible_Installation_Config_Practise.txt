Ansible Installation & Configurations:

Launch 3 EC2 Instances... 1 for Ansible Controller & 2 as Nodes

SSH connections :::

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#Login to Ansible Node1 & Node2. Perform below activities:

#Add User in Ansible Nodes : 

sudo -i

apt update -y 

useradd ansibleadmin -s /bin/bash -m -d /home/ansibleadmin 

passwd ansibleadmin

#Enter New Password:
#Confirm Password:

#Goto:

vi /etc/ssh/sshd_config

#Enable Password Authentication to Yes and save the file
#Execute Below command to update the changes.

service sshd reload

#As a root user edit below file:
$ visudo

#add the below mentioned line in the file and save it.
ansibleadmin ALL=(ALL) NOPASSWD: ALL

su - ansibleadmin

ls -a 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

#Login to Ansible Controller: https://docs.ansible.com/ansible/latest/installation_guide/index.html

sudo -i

sudo apt update -y

sudo apt install software-properties-common -y

sudo add-apt-repository --yes --update ppa:ansible/ansible

sudo apt update -y

sudo apt install ansible -y

ansible --version

#go to /etc/ansible

#host - inventory file
#config
#roles 

#Add User in Ansible Controller : 

useradd devopsadmin -s /bin/bash -m -d /home/devopsadmin

#useradd devopsadmin

su - devopsadmin	

ssh-keygen -t rsa -b 1024 -m PEM

ssh-copy-id ansibleadmin@172.31.34.167
ssh-copy-id ansibleadmin@172.31.32.44

ssh ansibleadmin@172.31.34.167
ssh ansibleadmin@172.31.32.44

chown -R devopsadmin:devopsadmin /etc/ansible


###update vi etc/ansible/host

[testnodes]
samplenode1 ansible_ssh_host=172.31.34.167 ansible_ssh_user=ansibleadmin
samplenode2 ansible_ssh_host=172.31.32.44 ansible_ssh_user=ansibleadmin

[DEVTEAM]
devnode1 ansible_ssh_host=172.31.34.167 ansible_ssh_user=ansibleadmin

[SharedResources]
devnode1222 ansible_ssh_host=172.31.34.167 ansible_ssh_user=ansibleadmin

[TESTTEAM]
samplenode2 ansible_ssh_host=172.31.34.167 ansible_ssh_user=ansibleadmin
testnode2 ansible_ssh_host=172.31.32.44 ansible_ssh_user=ansibleadmin


#**************************************************************************************************************************
#hosts file is the default Inventory file for ansible 
#**************************************************************************************************************************
#Access thru Ansible Controller :
#**************************************************************************************************************************

ansible <hosts_name> -m <module_name> -i <inventory_file>

ansible testnodes -m ping

ansible dev_server_grp1 -m ping -i dev_servers

#host machines can be identified using :
#all | group_name | individual_host_name


###update vi /etc/ansible/host

[testnodes]
samplenode1 ansible_ssh_host=172.31.41.32 ansible_ssh_user=ansibleadmin
samplenode2 ansible_ssh_host=172.31.39.17 ansible_ssh_user=ansibleadmin


/etc/ansible/dev_inventory

[devnodes]
sampledevnode1 ansible_ssh_host=172.31.41.32 ansible_ssh_user=ansibleadmin
sampledevnode2 ansible_ssh_host=172.31.39.17 ansible_ssh_user=ansibleadmin

ansible devnodes -m ping -i /etc/ansible/dev_inventory


##################################################################################

#**************************************************************************************************************************
#Access thru Ansible Controller :
#**************************************************************************************************************************
Ansible Modules: Eg.: 
ansible testnodes -m ping

ansible all -m ping ### will ping all hosts from /etc/ansible/hosts file

ansible samplenode1 -m ping
ansible samplenode2 -m ping

#or using user defined Inventory file
#ansible ansible-node1 -m ping -i myinventoryfile.txt


ansible samplenode1 -m ping -i myinventoryfile.txt

#**************************************************************************************************************************

ansible samplenode2 -m ping


ansible samplenode1 -m shell -a "sleep 5 ; echo 'hi'"

#**************************************************************************************************************************
#Ansible Variables !
#shell : echo $var1 

in yaml : "{{var1}}"



#debugmod.yaml

---
 - hosts: testnodes
   tasks:
   - debug:  
      msg:
       - "The os distribution is: {{ansible_distribution}}" 
       - "THe os name is: {{ansible_system}}"
       - "The os family is: {{ansible_os_family}}"
       - "THe mount points are :{{ansible_mounts}}"
	   
	   
	Execute :::
	
			ansible-playbook debugmod.yaml 
			
#**************************************************************************************************
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#~~~~~~~~~~~~~~~~~~~~~~~~~ test_var-datatype.yaml
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#test_var-datatype.yaml
---
 - hosts: samplenode1
   vars:
    x: 23
    my_num: 45.67
    my_name: Loksai
    my_b: YES   
   tasks:
   - debug:
      msg:
       - "The value of x is: {{x}} and type: {{x|type_debug}}"
       - "THe value of my_num: {{my_num}} and type : {{my_num|type_debug}}"
       - "The value of my_name : {{my_name}} and type: {{my_name|type_debug}}"
       - "The value of my_b is: {{my_b}} and type : {{my_b|type_debug}}"



---
 - hosts: samplenode1
   gather_facts: false
   become: yes
   tasks:
   - name: Manage git tool
     apt:
       name: git
       state: present

apt/yum/dnf ==> package management modules :

state : present / absent / latest 
yum/apt ::

state : present / absent / latest 
yum install git 
yum remove git 
yum update git 





#install3.yaml
---
 - hosts: "{{ host_name }}"
   become: yes
   tasks:
   - name: Manage "{{ tool_name }}" service
     apt:
       name: "{{ tool_name }}"
       state: "{{ tool_state }}"




ansible-playbook install2.yaml -e "host_name=samplenode1 tool_name=git tool_state=present"



#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#~~~~~~~~~~~~~~~~~~~~~~~~~ register and set-facts
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

#test_var-datatype.yaml
---
 - hosts: samplenode1
   gather_facts: false
   tasks:
   - shell: "bash --version"



#test_var-datatype.yaml
---
 - hosts: samplenode1
   tasks:
   - shell: "bash --version"
     register: bash_ver
   - debug: var=bash_ver

   
#register_set_facts.yaml
---
 - hosts: samplenode1
   tasks:
   - shell: "bash --version"
     register: bash_ver
   - set_fact:
      bash_version: "{{bash_ver.stdout.split('\n')[0].split()[3]}}"
      my_value: "bash version"
   - debug: var=bash_version
   
Handlers :::

---
  - hosts: samplenode1
    #gather_facts: false
    become: yes
    tasks:
      - name: Install-httpd
        yum:
          name: httpd
          state: present
        notify:
        - start-httpd
    handlers:
    - name: start-httpd
      service:
          name: httpd
          state: started
		  
Handlers --> are used to controll the flow of playbook execution, based on the previous modules
		This can be done thru notify key.

		Handlers are same as tasks.


Loops :

---
  - hosts: samplenode1
    become: yes
    tasks:
      - yum:
         name: git
         state: present
      - yum:
         name: tree
         state: present
      - yum:
         name: vim
         state: present












Loops :::

---
  - hosts: samplenode1
    gather_facts: false
    become: yes
    tasks:
      - apt:
         name: "{{item}}"
         state: absent
        loop:
          - git
          - nginx
          - tree
 
#~~~~~~~~~~~~~~~~~~~~~~~~~
Ansible Roles :::


		Ansible Roles are used to organize the Ansible Components
		To reuse & Share.

		Ansible Repository ::

		Understand the structure of Ansible Components ::::

			playbooks, handlers, loop, variable, defaults, tasks,
			
			





